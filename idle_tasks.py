"""
idle_tasks.py  â€”â€”  ç©ºé—²æ—¶æ®µä»»åŠ¡è°ƒåº¦å™¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

è§¦å‘æ¡ä»¶ï¼š
  1. éäº¤æ˜“æ—¶æ®µ (ç›˜å‰/ç›˜å/æ·±å¤œ)
  2. å½“å‰æ— æŒä»“ (æœ‰æŒä»“æ—¶ä¸åšåå°ä»»åŠ¡ï¼Œä¸“æ³¨ç›‘æ§)
  3. è·ä¸Šæ¬¡æ‰§è¡Œ >= æœ€å°é—´éš”

ä»»åŠ¡åˆ—è¡¨ï¼š
  Task A  æ–°é—»é‡‡é›†        æ¯ 1 å°æ—¶  é‡‡é›†12åªè‚¡ç¥¨æœ€æ–°æ–°é—»æ ‡é¢˜
  Task B  æƒ…ç»ªåˆ†æ        æ¯ 1 å°æ—¶  Claudeåˆ†ææ¯åªè‚¡ç¥¨ bullish/bearish/neutral
  Task C  MEMORY.mdæ›´æ–°  æ¯ 2 å°æ—¶  æŠŠæƒ…ç»ª+æ–°é—»å†™å…¥çŸ¥è¯†åº“
  Task D  æ˜¨æ—¥å›æµ‹        æ¯å¤© 00:00  å›æµ‹æ˜¨æ—¥ç­–ç•¥çš„å®é™…å‡†ç¡®ç‡

ç»“æœé€šè¿‡ heartbeat.send_idle_report() ä¸ŠæŠ¥åˆ°ä¼ä¸šå¾®ä¿¡
"""

import re
import time
import json
import logging
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import anthropic

from config import STOCKS, ANTHROPIC_API_KEY
from heartbeat import send_idle_report, log_signal, log_error

logger = logging.getLogger("idle_tasks")

claude = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# â”€â”€ ä»»åŠ¡æ‰§è¡Œæ—¶é—´è¿½è¸ª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_last_run: Dict[str, float] = {
    "news":    0.0,
    "sentiment": 0.0,
    "memory":  0.0,
    "backtest": 0.0,
}

# æœ€å°é—´éš” (ç§’)
TASK_INTERVALS = {
    "news":      1 * 3600,    # 1å°æ—¶
    "sentiment": 1 * 3600,    # 1å°æ—¶
    "memory":    2 * 3600,    # 2å°æ—¶
    "backtest":  24 * 3600,   # æ¯å¤©ä¸€æ¬¡
}

# â”€â”€ æ–°é—» + æƒ…ç»ªç¼“å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_news_cache: Dict[str, List[str]] = {}      # ticker â†’ [headline1, ...]
_sentiment_cache: Dict[str, Dict] = {}      # ticker â†’ {sentiment, score, summary}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Task A  æ–°é—»é‡‡é›†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _fetch_news_for_ticker(ticker: str) -> List[str]:
    """
    ç”¨ DuckDuckGo æœç´¢æœ€æ–°æ–°é—»æ ‡é¢˜
    è¿”å›æœ€å¤š5æ¡æ ‡é¢˜
    """
    try:
        query = f"{ticker} stock news today earnings"
        url = f"https://api.duckduckgo.com/?q={query}&format=json&no_redirect=1"
        r = requests.get(url, timeout=10,
                         headers={"User-Agent": "Mozilla/5.0"})
        data = r.json()

        headlines = []
        # AbstractText æ˜¯æ‘˜è¦
        if data.get("AbstractText"):
            headlines.append(data["AbstractText"][:200])

        # RelatedTopics é‡Œæœ‰æ›´å¤š
        for topic in data.get("RelatedTopics", [])[:4]:
            if isinstance(topic, dict) and topic.get("Text"):
                headlines.append(topic["Text"][:200])

        return headlines[:5]

    except Exception as e:
        logger.warning(f"News fetch failed for {ticker}: {e}")
        return []


def run_news_collection() -> Dict[str, List[str]]:
    """
    Task A: é‡‡é›†æ‰€æœ‰12åªè‚¡ç¥¨æ–°é—»
    è¿”å› {ticker: [headlines]}
    """
    logger.info("ğŸ“° Task A: Starting news collection...")
    results = {}
    success = 0

    for ticker in STOCKS:
        headlines = _fetch_news_for_ticker(ticker)
        results[ticker] = headlines
        if headlines:
            success += 1
        time.sleep(0.5)   # é¿å…è¯·æ±‚è¿‡å¿«

    _news_cache.update(results)
    logger.info(f"News collection done: {success}/{len(STOCKS)} stocks got news")

    summary_lines = []
    for ticker, hl in results.items():
        count = len(hl)
        preview = hl[0][:60] + "..." if hl else "æ— æ–°é—»"
        summary_lines.append(f"> ğŸ“Œ **{ticker}** ({count}æ¡): {preview}")

    send_idle_report("ğŸ“° æ–°é—»é‡‡é›†å®Œæˆ", "\n".join(summary_lines[:8]))
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Task B  æƒ…ç»ªåˆ†æ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _analyze_sentiment_batch(news_map: Dict[str, List[str]]) -> Dict[str, Dict]:
    """
    Claudeæ‰¹é‡åˆ†æ12åªè‚¡ç¥¨æƒ…ç»ª
    ä¸€æ¬¡APIè°ƒç”¨å¤„ç†å…¨éƒ¨ï¼ˆçœtokenï¼‰
    """
    if not any(news_map.values()):
        logger.warning("No news to analyze")
        return {}

    # æ„å»ºè¾“å…¥æ–‡æœ¬
    news_text = ""
    for ticker, headlines in news_map.items():
        if headlines:
            news_text += f"\n[{ticker}]\n"
            for h in headlines:
                news_text += f"- {h}\n"

    prompt = f"""åˆ†æä»¥ä¸‹è‚¡ç¥¨æ–°é—»çš„æƒ…ç»ªï¼Œå¯¹æ¯åªè‚¡ç¥¨ç»™å‡ºï¼š
1. sentiment: bullish / bearish / neutral
2. score: -1.0 åˆ° 1.0 (bullish=æ­£, bearish=è´Ÿ)
3. summary: ä¸€å¥è¯åŸå›  (ä¸­æ–‡, â‰¤30å­—)

æ–°é—»å†…å®¹:
{news_text}

è¿”å›JSONæ ¼å¼ï¼Œä¾‹å¦‚ï¼š
{{
  "NVDA": {{"sentiment": "bullish", "score": 0.8, "summary": "æ•°æ®ä¸­å¿ƒéœ€æ±‚å¼ºåŠ²ï¼ŒQ4è¶…é¢„æœŸ"}},
  "TSLA": {{"sentiment": "bearish", "score": -0.6, "summary": "ä»·æ ¼æˆ˜æŒç»­ï¼Œæ¬§æ´²é”€é‡ä¸‹æ»‘"}}
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

    try:
        resp = claude.messages.create(
            model="claude-opus-4-6",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        raw = resp.content[0].text.strip()
        raw = re.sub(r"```json|```", "", raw).strip()
        result = json.loads(raw)
        logger.info(f"Sentiment analysis done: {len(result)} stocks")
        return result

    except json.JSONDecodeError as e:
        log_error(f"Sentiment JSON parse failed: {e}")
        return {}
    except Exception as e:
        log_error(f"Sentiment analysis API error: {e}")
        return {}


def run_sentiment_analysis() -> Dict[str, Dict]:
    """
    Task B: åˆ†ææƒ…ç»ª
    ä¾èµ– _news_cacheï¼Œå»ºè®®åœ¨ run_news_collection() ä¹‹åè°ƒç”¨
    """
    logger.info("ğŸ§  Task B: Starting sentiment analysis...")

    news_to_analyze = _news_cache if _news_cache else {}
    if not news_to_analyze:
        logger.warning("No news in cache, skipping sentiment")
        return {}

    results = _analyze_sentiment_batch(news_to_analyze)
    _sentiment_cache.update(results)

    # æ ¼å¼åŒ–ä¸ŠæŠ¥
    bullish  = [t for t, v in results.items() if v.get("sentiment") == "bullish"]
    bearish  = [t for t, v in results.items() if v.get("sentiment") == "bearish"]
    neutral  = [t for t, v in results.items() if v.get("sentiment") == "neutral"]

    lines = [
        f"> ğŸ“ˆ **Bullish** ({len(bullish)}åª): {', '.join(bullish) or 'æ— '}",
        f"> ğŸ“‰ **Bearish** ({len(bearish)}åª): {', '.join(bearish) or 'æ— '}",
        f"> â– **Neutral** ({len(neutral)}åª): {', '.join(neutral) or 'æ— '}",
        "",
    ]
    # è¯¦æƒ…
    for ticker, v in results.items():
        emoji = "ğŸ“ˆ" if v.get("sentiment") == "bullish" else \
                "ğŸ“‰" if v.get("sentiment") == "bearish" else "â–"
        score = v.get("score", 0)
        lines.append(f"> {emoji} **{ticker}** `{score:+.1f}` â€” {v.get('summary','')}")

    send_idle_report("ğŸ§  æƒ…ç»ªåˆ†æå®Œæˆ", "\n".join(lines))

    # åŒæ—¶è®°å½•ä¿¡å·
    for ticker, v in results.items():
        if abs(v.get("score", 0)) >= 0.6:
            log_signal(ticker, "news_alert",
                       f"{v['sentiment']} score={v['score']:+.1f}: {v.get('summary','')}")

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Task C  æ›´æ–° MEMORY.md çŸ¥è¯†åº“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_memory_update(sentiment_map: Optional[Dict] = None,
                      memory_file: str = "MEMORY.md") -> bool:
    """
    Task C: å°†ä»Šæ—¥æ–°é—»æƒ…ç»ªå†™å…¥ MEMORY.md
    è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾ï¼Œä¿ç•™å†å²è®°å½•
    """
    logger.info("ğŸ“ Task C: Updating MEMORY.md...")
    sm = sentiment_map or _sentiment_cache

    if not sm:
        logger.warning("No sentiment data to write to memory")
        return False

    today_str = datetime.now().strftime("%Y-%m-%d")
    lines = [
        f"\n## ğŸ“° {today_str} å¸‚åœºæƒ…ç»ªå¿«ç…§\n",
        f"*è®°å½•æ—¶é—´: {datetime.now().strftime('%H:%M')}*\n\n",
        "| è‚¡ç¥¨ | æƒ…ç»ª | åˆ†æ•° | æ‘˜è¦ |\n",
        "|------|------|------|------|\n",
    ]
    for ticker in sorted(sm.keys()):
        v = sm[ticker]
        sentiment = v.get("sentiment", "neutral")
        score     = v.get("score", 0.0)
        summary   = v.get("summary", "")
        emoji     = "ğŸ“ˆ" if sentiment == "bullish" else \
                    "ğŸ“‰" if sentiment == "bearish" else "â–"
        lines.append(f"| **{ticker}** | {emoji} {sentiment} | `{score:+.2f}` | {summary} |\n")

    # è¿½åŠ å†™å…¥
    try:
        with open(memory_file, "a", encoding="utf-8") as f:
            f.writelines(lines)
        logger.info(f"MEMORY.md updated with {len(sm)} stocks")

        send_idle_report(
            "ğŸ“ MEMORY.md å·²æ›´æ–°",
            f"> å†™å…¥ {len(sm)} åªè‚¡ç¥¨ä»Šæ—¥æƒ…ç»ª\n> æ–‡ä»¶: `{memory_file}`"
        )
        return True
    except Exception as e:
        log_error(f"MEMORY.md write failed: {e}")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Task D  æ˜¨æ—¥å›æµ‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _load_yesterdays_signals(memory_file: str = "MEMORY.md") -> List[Dict]:
    """
    ä» MEMORY.md è¯»å–æ˜¨æ—¥è®°å½•çš„ trade_entered ä¿¡å·
    ï¼ˆæ ¼å¼: ä¸Šæ¬¡äº¤æ˜“è®°å½•çš„ ticker, short_price ç­‰ï¼‰
    """
    signals = []
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    try:
        with open(memory_file, "r", encoding="utf-8") as f:
            content = f.read()
        # ç®€å•è§£æ: æ‰¾ "## YYYY-MM-DD Trade:" æ ¼å¼çš„è¡Œ
        pattern = rf"## {yesterday}.*?ticker=(\w+).*?short_price=\$([\d.]+)"
        for match in re.finditer(pattern, content):
            signals.append({
                "ticker": match.group(1),
                "short_price": float(match.group(2))
            })
    except FileNotFoundError:
        logger.info("MEMORY.md not found for backtest")
    except Exception as e:
        logger.warning(f"Load signals failed: {e}")
    return signals


def _get_yesterdays_close(ticker: str) -> Optional[float]:
    """ç”¨ yfinance è·å–æ˜¨æ—¥æ”¶ç›˜ä»·"""
    try:
        import yfinance as yf
        hist = yf.Ticker(ticker).history(period="2d")
        if len(hist) >= 1:
            return float(hist["Close"].iloc[-1])
    except Exception as e:
        logger.warning(f"yfinance failed for {ticker}: {e}")
    return None


def run_backtest() -> Dict:
    """
    Task D: å›æµ‹æ˜¨æ—¥ç­–ç•¥å‡†ç¡®ç‡
    
    é€»è¾‘ï¼š
    - è¯»å–æ˜¨æ—¥è¿›å…¥çš„ç©ºä»“ä¿¡å· (from MEMORY.md)
    - è·å–ä»Šæ—¥æ”¶ç›˜ä»·
    - å¦‚æœæ”¶ç›˜ä»· < ç©ºä»“ä»· â†’ æ–¹å‘æ­£ç¡® (profit)
    - å¦‚æœæ”¶ç›˜ä»· > ç©ºä»“ä»· â†’ æ–¹å‘é”™è¯¯ (loss)
    - è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
    """
    logger.info("ğŸ”¬ Task D: Running backtest...")

    yesterday_signals = _load_yesterdays_signals()
    if not yesterday_signals:
        logger.info("No signals from yesterday to backtest")
        send_idle_report("ğŸ”¬ æ˜¨æ—¥å›æµ‹", "> æ˜¨æ—¥æ— äº¤æ˜“ä¿¡å·å¯å›æµ‹")
        return {"accuracy": None, "total": 0}

    results = []
    for sig in yesterday_signals:
        ticker      = sig["ticker"]
        short_price = sig["short_price"]
        close_price = _get_yesterdays_close(ticker)

        if close_price is None:
            continue

        correct = close_price < short_price   # ç©ºä»“åä¸‹è·Œ = æ­£ç¡®
        pnl_pct = (short_price - close_price) / short_price * 100
        results.append({
            "ticker": ticker,
            "short_price": short_price,
            "close": close_price,
            "correct": correct,
            "pnl_pct": pnl_pct
        })

    if not results:
        return {"accuracy": None, "total": 0}

    correct_count = sum(1 for r in results if r["correct"])
    accuracy      = correct_count / len(results) * 100

    # æ ¼å¼åŒ–ä¸ŠæŠ¥
    lines = [f"> **å‡†ç¡®ç‡: {accuracy:.0f}%** ({correct_count}/{len(results)})\n"]
    for r in results:
        emoji   = "âœ…" if r["correct"] else "âŒ"
        pnl_str = f"+{r['pnl_pct']:.1f}%" if r["pnl_pct"] >= 0 else f"{r['pnl_pct']:.1f}%"
        lines.append(
            f"> {emoji} **{r['ticker']}** | "
            f"ç©º: ${r['short_price']:.2f} â†’ æ”¶: ${r['close']:.2f} | {pnl_str}"
        )

    send_idle_report("ğŸ”¬ æ˜¨æ—¥ç­–ç•¥å›æµ‹", "\n".join(lines))

    return {
        "accuracy": accuracy,
        "correct":  correct_count,
        "total":    len(results),
        "details":  results
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ç©ºé—²ä»»åŠ¡è°ƒåº¦å™¨  â€”â€”  åœ¨ä¸»å¾ªç¯ä¸­è°ƒç”¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class IdleTaskScheduler:
    """
    åœ¨ä¸»å¾ªç¯ç©ºé—²æ—¶æŒ‰æ—¶é—´é—´éš”è¿è¡Œåå°ä»»åŠ¡
    
    ç”¨æ³•:
        scheduler = IdleTaskScheduler()
        
        # åœ¨ä¸»å¾ªç¯åˆ¤æ–­ç©ºé—²æ—¶:
        if not has_active_position and not is_market_hours:
            scheduler.tick()
    """

    def __init__(self):
        self._last_run = {k: 0.0 for k in TASK_INTERVALS}
        self._is_running = False

    def _should_run(self, task: str) -> bool:
        elapsed = time.time() - self._last_run[task]
        return elapsed >= TASK_INTERVALS[task]

    def _mark_done(self, task: str):
        self._last_run[task] = time.time()

    def tick(self, has_position: bool = False) -> List[str]:
        """
        æ£€æŸ¥å¹¶è¿è¡Œåˆ°æœŸçš„ç©ºé—²ä»»åŠ¡
        
        Args:
            has_position: æ˜¯å¦æœ‰æ´»è·ƒæŒä»“ï¼ˆæœ‰æŒä»“æ—¶è·³è¿‡æ‰€æœ‰ä»»åŠ¡ï¼‰
        
        Returns:
            æœ¬æ¬¡è¿è¡Œçš„ä»»åŠ¡ååˆ—è¡¨
        """
        if has_position:
            logger.debug("Has active position, skipping idle tasks")
            return []

        if self._is_running:
            logger.debug("Idle tasks already running, skipping")
            return []

        self._is_running = True
        ran = []

        try:
            # Task A: æ–°é—»é‡‡é›†
            if self._should_run("news"):
                logger.info("â° Running idle task: news collection")
                run_news_collection()
                self._mark_done("news")
                ran.append("news")

            # Task B: æƒ…ç»ªåˆ†æ (ä¾èµ–æ–°é—»ç¼“å­˜)
            if self._should_run("sentiment") and _news_cache:
                logger.info("â° Running idle task: sentiment analysis")
                run_sentiment_analysis()
                self._mark_done("sentiment")
                ran.append("sentiment")

            # Task C: æ›´æ–° MEMORY.md
            if self._should_run("memory") and _sentiment_cache:
                logger.info("â° Running idle task: memory update")
                run_memory_update()
                self._mark_done("memory")
                ran.append("memory")

            # Task D: æ˜¨æ—¥å›æµ‹ (æ¯å¤©åˆå¤œè·‘ä¸€æ¬¡)
            if self._should_run("backtest"):
                now_hour = datetime.now().hour
                if 0 <= now_hour < 2:   # åªåœ¨ 00:00-02:00 è¿è¡Œ
                    logger.info("â° Running idle task: backtest")
                    run_backtest()
                    self._mark_done("backtest")
                    ran.append("backtest")

        except Exception as e:
            log_error(f"Idle task failed: {e}")
        finally:
            self._is_running = False

        if ran:
            logger.info(f"Idle tasks completed: {ran}")
        return ran


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æœ¬åœ°æµ‹è¯•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    print("=== ç©ºé—²ä»»åŠ¡è°ƒåº¦å™¨æµ‹è¯• ===\n")

    # æµ‹è¯•æƒ…ç»ªåˆ†ææ ¼å¼ (ä¸è°ƒç”¨çœŸå®API)
    mock_sentiment = {
        "NVDA": {"sentiment": "bullish",  "score": 0.85, "summary": "æ•°æ®ä¸­å¿ƒéœ€æ±‚æš´å¢"},
        "TSLA": {"sentiment": "bearish",  "score": -0.70, "summary": "é™ä»·ç«äº‰æŸå®³åˆ©æ¶¦"},
        "AAPL": {"sentiment": "neutral",  "score": 0.10, "summary": "æ— é‡å¤§æ–°é—»"},
        "META": {"sentiment": "bullish",  "score": 0.60, "summary": "å¹¿å‘Šä¸šåŠ¡è¶…é¢„æœŸ"},
        "MSFT": {"sentiment": "bullish",  "score": 0.55, "summary": "Azureäº‘å¢é•¿å¼ºåŠ²"},
        "AMD":  {"sentiment": "bearish",  "score": -0.40, "summary": "PCç«¯éœ€æ±‚ç–²è½¯"},
    }

    print("æ¨¡æ‹Ÿæƒ…ç»ªåˆ†æç»“æœ:")
    for t, v in mock_sentiment.items():
        emoji = "ğŸ“ˆ" if v["sentiment"] == "bullish" else "ğŸ“‰" if v["sentiment"] == "bearish" else "â–"
        print(f"  {emoji} {t:6s} score={v['score']:+.2f}  {v['summary']}")

    print("\næ¨¡æ‹Ÿ MEMORY.md å†™å…¥...")
    run_memory_update(mock_sentiment, memory_file="/tmp/MEMORY_TEST.md")
    print("å·²å†™å…¥ /tmp/MEMORY_TEST.md")

    print("\n=== è°ƒåº¦å™¨çŠ¶æ€ ===")
    scheduler = IdleTaskScheduler()
    print("tasks:", list(scheduler._last_run.keys()))
    print("all should_run:", [t for t in TASK_INTERVALS if scheduler._should_run(t)])
